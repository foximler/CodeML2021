{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d8000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 03:42:32.449268: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-28 03:42:32.478853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.502866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.502996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.855701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.855849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.855955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-28 03:42:32.856056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 5561 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "# my output was => ['/device:CPU:0']\n",
    "# good output must be => ['/device:CPU:0', '/device:GPU:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b648abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as f_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54f58e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "\n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - removes punctuation\n",
    "        - removes any single character tokens\n",
    "        - removes emojies\n",
    "        \"\"\"\n",
    "    # Lowercase the twit message\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = message.lower()\n",
    "    test = emoji_pattern.sub(r' ', text)\n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub('https?:\\/\\/[a-zA-Z0-9@:%._\\/+~#=?&;-]*', ' ', text)\n",
    "    # Replace everything not a letter or apostrophe with a space\n",
    "    text = re.sub('[^a-zA-Z\\']', ' ', text)\n",
    "    # Remove single letter words\n",
    "    text = ' '.join( [w for w in text.split() if len(w)>1] )\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a39d64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = 'train.csv'\n",
    "messages = []\n",
    "subreddits = []\n",
    "with open(csv_file, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        messages.append(row.get('text'))\n",
    "        subreddits.append(row.get('subreddit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2cf56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = [preprocess(message) for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72bf5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jokes', 'SubredditSimulator', 'antiwork', 'wallstreetbets', 'worldnews'}\n"
     ]
    }
   ],
   "source": [
    "setofsubs = set(subreddits)\n",
    "print(setofsubs)\n",
    "# convert all different sub values into integer\n",
    "def subreddittonum(shortsub):\n",
    "    return {\n",
    "            'worldnews': 0,\n",
    "            'Jokes': 1,\n",
    "            'antiwork': 2,\n",
    "            'SubredditSimulator': 3,\n",
    "            'wallstreetbets': 4,\n",
    "\n",
    "    }[shortsub]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "420b3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [subreddittonum(subreddit) for subreddit in subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c35cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset, info = preprocessed, subreddits\n",
    "dataset_train, dataset_test, info_train, info_test = train_test_split(dataset, info, test_size=0.05)\n",
    "#we use one_hot because we are trying to classify for 5 different classes. so we create an array. A smarter programmer would do this in the text to num function but im not smarter. \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dataset_train, tf.one_hot(info_train, depth=len(setofsubs))))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dataset_test, tf.one_hot(info_test, depth=len(setofsubs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94a87748",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 500\n",
    "#smol epoch to 2070 super doesnt cry.\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64de606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41da3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 6900\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1db67de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_double = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(124,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(124)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec2f2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_double.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8f7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3488/3488 [==============================] - 145s 39ms/step - loss: 0.2347 - accuracy: 0.7340 - val_loss: 0.1541 - val_accuracy: 0.8417\n",
      "Epoch 2/4\n",
      "3488/3488 [==============================] - 116s 33ms/step - loss: 0.1271 - accuracy: 0.8765 - val_loss: 0.1575 - val_accuracy: 0.8500\n",
      "Epoch 3/4\n",
      "2221/3488 [==================>...........] - ETA: 45s - loss: 0.0961 - accuracy: 0.9094"
     ]
    }
   ],
   "source": [
    "model_old = model_double #0.8667\n",
    "history_double = model_double.fit(train_dataset, epochs=4,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76e8a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numtosub(shortsub):\n",
    "    return {\n",
    "            0:'worldnews',\n",
    "            1:'Jokes',\n",
    "            2:'antiwork',\n",
    "            3:'SubredditSimulator',\n",
    "            4:'wallstreetbets',\n",
    "\n",
    "    }[shortsub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ab3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 04:39:46.305053: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:39:46.305078: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:41:19.312733: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:41:19.312758: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:42:03.590148: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:42:03.590169: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:42:56.360519: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:42:56.360569: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:43:35.836263: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:43:35.836318: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:44:49.249973: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:44:49.250002: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:44:58.645292: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:44:58.645318: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:45:23.730821: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:45:23.730988: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:45:28.486560: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:45:28.486585: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:14.580282: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:14.580304: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:47.945788: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:47.945962: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:49.194711: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n",
      "2021-11-28 04:46:49.194746: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file = 'test_text.csv'\n",
    "messages_test = []\n",
    "subreddits_test = []\n",
    "iteration = 0\n",
    "with open(csv_file, 'r') as ayylmao:\n",
    "    reader = csv.DictReader(ayylmao)\n",
    "    for row in reader:\n",
    "        iteration = iteration+1\n",
    "        message = preprocess(row.get('text'))\n",
    "        messages_test.append(message)\n",
    "        try:\n",
    "            sub = numtosub(np.argmax(model_old.predict(np.array([message]))))\n",
    "        except:\n",
    "            sub = \"SubredditSimulator\"\n",
    "        subreddits_test.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d6a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv for upload\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"test_text.csv\")\n",
    "df[\"id\"] = df.reset_index().index\n",
    "df[\"subreddit\"] = subreddits_test\n",
    "df.to_csv(\"final_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf125bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
